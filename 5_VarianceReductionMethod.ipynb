{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.stats import chi2, kstest, norm\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Crude Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.743309935963331\n",
      "[1.65 1.84]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "def MonteCarlo(n):\n",
    "    U = np.random.uniform(0, 1, n)\n",
    "    X = np.exp(U)\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    standard_error = std / np.sqrt(n)\n",
    "    confidence_interval = (mean - 1.96 * standard_error, mean + 1.96 * standard_error)\n",
    "    return mean, confidence_interval\n",
    "\n",
    "\n",
    "mean, confidence_interval = MonteCarlo(100)\n",
    "print(mean)\n",
    "print(np.round(confidence_interval,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antithetic Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7282853392863842\n",
      "[1.63 1.83]\n"
     ]
    }
   ],
   "source": [
    "def AntitheticVariables(n):\n",
    "\n",
    "    U = np.random.uniform(0, 1, n//2)\n",
    "\n",
    "    combined_samples = np.concatenate([U, 1-U])\n",
    "\n",
    "    X = np.exp(combined_samples)\n",
    "\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    standard_error = std / np.sqrt(n)\n",
    "    confidence_interval = (mean - 1.96 * standard_error, mean + 1.96 * standard_error)\n",
    "\n",
    "    return mean, confidence_interval\n",
    "\n",
    "\n",
    "mean, confidence_interval = AntitheticVariables(100)\n",
    "print(mean)\n",
    "print(np.round(confidence_interval,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Varible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7765263059216747\n",
      "[1.74 1.82]\n"
     ]
    }
   ],
   "source": [
    "def ControlVariables(n):\n",
    "\n",
    "    U = np.random.uniform(0, 1, n//2)\n",
    "\n",
    "    X = np.exp(U)\n",
    "    control_var = U\n",
    "\n",
    "    expected_control_var = 0.5\n",
    "\n",
    "    alpha = -1  \n",
    "    control_variate_estimator = X + alpha * (control_var - expected_control_var)\n",
    "\n",
    "    mean = np.mean(control_variate_estimator)\n",
    "\n",
    "    std = np.std(control_variate_estimator)\n",
    "\n",
    "    standard_error = std / np.sqrt(n)\n",
    "\n",
    "    confidence_interval = (mean - 1.96 * standard_error, mean + 1.96 * standard_error)\n",
    "\n",
    "    return mean, confidence_interval\n",
    "\n",
    "\n",
    "mean, confidence_interval = ControlVariables(100)\n",
    "print(mean)\n",
    "print(np.round(confidence_interval,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7097066831022851\n",
      "[1.67 1.75]\n"
     ]
    }
   ],
   "source": [
    "def StratifiedSampling(n):\n",
    "\n",
    "    k = 10  # number of strata\n",
    "    samples_per_stratum = n // k\n",
    "\n",
    "    # Generate stratified samples\n",
    "    stratified_samples = []\n",
    "    for i in range(k):\n",
    "        stratum_samples = np.random.uniform(i / k, (i + 1) / k, samples_per_stratum)\n",
    "        stratified_samples.extend(stratum_samples)\n",
    "\n",
    "    U = np.array(stratified_samples)\n",
    "\n",
    "    X = np.exp(U)\n",
    "\n",
    "    mean = np.mean(X)\n",
    "\n",
    "    std = np.std(X)\n",
    "\n",
    "    standard_error = std / np.sqrt(n)\n",
    "\n",
    "    confidence_interval = (mean - 1.96 * standard_error, mean + 1.96 * standard_error)\n",
    "\n",
    "    return mean, confidence_interval\n",
    "\n",
    "\n",
    "mean, confidence_interval = ControlVariables(100)\n",
    "print(mean)\n",
    "print(np.round(confidence_interval,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Mean Value:\n",
      "1.72 \n",
      "\n",
      "Monte Carlo:\n",
      "1.7352            [1.64 1.84]          0.0152 \n",
      "\n",
      "Antithetic Variables:\n",
      "1.7192            [1.62 1.82]          0.0008 \n",
      "\n",
      "Control Variables:\n",
      "1.7311            [1.7  1.77]          0.0111 \n",
      "\n",
      "Stratified Sampling:\n",
      "1.7187            [1.62 1.82]          0.0013 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "print('True Mean Value:')\n",
    "print('1.72 \\n')\n",
    "\n",
    "print('Monte Carlo:')\n",
    "mean, confidence_interval = MonteCarlo(n)\n",
    "print(np.round(mean,4),'          ',np.round(confidence_interval,2),'        ',np.round(np.abs(mean-1.72),4),'\\n')\n",
    "\n",
    "print('Antithetic Variables:')\n",
    "mean, confidence_interval = AntitheticVariables(n)\n",
    "print(np.round(mean,4),'          ',np.round(confidence_interval,2),'        ',np.round(np.abs(mean-1.72),4),'\\n')\n",
    "\n",
    "print('Control Variables:')\n",
    "mean, confidence_interval = ControlVariables(n)\n",
    "print(np.round(mean,4),'          ',np.round(confidence_interval,2),'        ',np.round(np.abs(mean-1.72),4),'\\n')\n",
    "\n",
    "print('Stratified Sampling:')\n",
    "mean, confidence_interval = StratifiedSampling(n)\n",
    "print(np.round(mean,4),'          ',np.round(confidence_interval,2),'        ',np.round(np.abs(mean-1.72),4),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redusing Variance of Exercise 4 with control variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of X:  2.421484000000001e-06\n",
      "variance of Z:  2.147183138949091e-06\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "m = 10                  \n",
    "mst = 8   \n",
    "mtbc = 1 \n",
    "N = 100000  \n",
    "n= 10   \n",
    "\n",
    "# set seed\n",
    "np.random.seed(123)\n",
    "\n",
    "def Exp_service_time(mst):\n",
    "    return np.random.exponential(mst)\n",
    "\n",
    "# Function to run a single simulation \n",
    "def Run_Poisson_Sim(m,mst,mtbc,n,N,service_dist):\n",
    "    \"\"\"\n",
    "    Runs a simulation of a blocking system with m service units.\n",
    "    \n",
    "    Input: \n",
    "    m = Service units \n",
    "    mst = Mean Service time \n",
    "    mtbc = mean time between customers\n",
    "    n = Number of simulations \n",
    "    N = number of customers\n",
    "\n",
    "    Output: \n",
    "    - Returns the fraction of blocked customers \n",
    "    \"\"\"\n",
    "    # Known expected value of the control variate (total idle time)\n",
    "    expected_service_time = N*mst\n",
    "\n",
    "    blocked_fractions = []\n",
    "    total_service_time = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Initialize parameters \n",
    "        t = 0\n",
    "        blocked_customers = 0\n",
    "        tot_ser_time = 0\n",
    "        busy_until = [0] * m\n",
    "\n",
    "        # loop over number of customers \n",
    "        for _ in range(N):\n",
    "            # Generate next arrival time\n",
    "            t += np.random.exponential(mtbc)\n",
    "            \n",
    "            # Check for an available server\n",
    "            available_server = -1\n",
    "            for i in range(m):\n",
    "                if busy_until[i] <= t:\n",
    "                    available_server = i\n",
    "                    break\n",
    "            \n",
    "            if available_server == -1:\n",
    "                # All servers are busy\n",
    "                blocked_customers += 1\n",
    "            else:\n",
    "                # Assign the customer to the available server\n",
    "                service_time = service_dist()\n",
    "                tot_ser_time += service_time\n",
    "                busy_until[available_server] = t + service_time\n",
    "\n",
    "\n",
    "        blocked_fractions.append(blocked_customers / N)\n",
    "        total_service_time.append(tot_ser_time)\n",
    "    \n",
    "\n",
    "    mean_blocked = np.mean(blocked_fractions)\n",
    "    mean_service_time = np.mean(total_service_time)\n",
    "\n",
    "    \n",
    "\n",
    "    variance_control_var = np.var(total_service_time)\n",
    "    if variance_control_var == 0:\n",
    "        raise ValueError(\"Control variable has zero variance, choose a different control variate.\")\n",
    "\n",
    "    cov = np.cov(blocked_fractions, total_service_time)[0, 1]\n",
    "    var = np.var(total_service_time)\n",
    "    alpha = cov / var\n",
    "\n",
    "    adjusted_blocking_fractions = [\n",
    "    bf - alpha * (cv - expected_service_time)\n",
    "    for bf, cv in zip(blocked_fractions, total_service_time)\n",
    "    ]  \n",
    "\n",
    "    #Variance: \n",
    "    varX = np.var(blocked_fractions)\n",
    "\n",
    "    varZ = varX - ((cov**2)/var )\n",
    "\n",
    "    print('variance of X: ', varX)\n",
    "    print('variance of Z: ', varZ)\n",
    "\n",
    "    mean = np.mean(adjusted_blocking_fractions)\n",
    "    std= np.std(adjusted_blocking_fractions)\n",
    "    conf_int = stats.norm.interval(0.95, loc=mean, scale=std / np.sqrt(n))\n",
    "\n",
    "    return adjusted_blocking_fractions,mean, conf_int\n",
    "\n",
    "def Erlang_B(A,m):\n",
    "    # Analytical calculation using Erlang's B-formula\n",
    "    return A**m / math.factorial(m)/ sum(A**i / math.factorial(i) for i in range(m + 1))\n",
    "\n",
    "generator = lambda: Exp_service_time(mst)\n",
    "# Run simulations\n",
    "blocked_fractions_1,mean_1, conf_int_1 = Run_Poisson_Sim(m,mst, mtbc,n,N,generator) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0000\n",
      "95% confidence interval: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "#Function for hyper exponential distribution\n",
    "def hyperexponential(p1, lambda1, p2, lambda2):\n",
    "    \n",
    "    if np.random.rand() < p1:\n",
    "        np.random.seed(42)\n",
    "        return np.random.exponential(1/lambda1)\n",
    "    else:\n",
    "        np.random.seed(42)\n",
    "        return np.random.exponential(1/lambda2)\n",
    "\n",
    "# Function to run a single simulation \n",
    "def CommonRandomNumbers(m,mst,mtbc,n,N,service_dist):\n",
    "    \n",
    "    blocked_fractions_poi = []\n",
    "    blocked_fractions_hype = []\n",
    "    \n",
    "    # Hyper-exponential distributed inter-arrival times\n",
    "    p1, lambda1 = 0.8, 0.8333\n",
    "    p2, lambda2 = 0.2, 5.0\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Initialize parameters \n",
    "        t_poi = 0\n",
    "        blocked_customers_poi = 0\n",
    "        busy_until_poi = [0] * m\n",
    "\n",
    "        t_hyp = 0\n",
    "        blocked_customers_hyp = 0\n",
    "        busy_until_hyp = [0] * m\n",
    "\n",
    "        # loop over number of customers \n",
    "        for _ in range(N):\n",
    "            # Generate next arrival time\n",
    "            np.random.seed(42)\n",
    "            t_poi += np.random.poisson(mtbc)\n",
    "            t_hyp += hyperexponential(p1, lambda1, p2, lambda2)\n",
    "            \n",
    "            # Check for an available server\n",
    "            available_server_poi = -1\n",
    "            for i in range(m):\n",
    "                if busy_until_poi[i] <= t_poi:\n",
    "                    available_server_poi = i\n",
    "                    break\n",
    "            \n",
    "            if available_server_poi == -1:\n",
    "                # All servers are busy\n",
    "                blocked_customers_poi += 1\n",
    "            else:\n",
    "                # Assign the customer to the available server\n",
    "                service_time = service_dist()\n",
    "                busy_until_poi[available_server_poi] = t_poi + service_time\n",
    "\n",
    "            #_____________________# \n",
    "\n",
    "            # Check for an available server\n",
    "            available_server_hyp = -1\n",
    "            for i in range(m):\n",
    "                if busy_until_hyp[i] <= t_hyp:\n",
    "                    available_server_hyp = i\n",
    "                    break\n",
    "            \n",
    "            if available_server_hyp == -1:\n",
    "                # All servers are busy\n",
    "                blocked_customers_hyp += 1\n",
    "            else:\n",
    "                # Assign the customer to the available server\n",
    "                service_time = service_dist()\n",
    "                busy_until_hyp[available_server_hyp] = t_hyp + service_time\n",
    "        \n",
    "        blocked_fractions_poi.append(blocked_customers_hyp / N)\n",
    "        blocked_fractions_hype.append(blocked_customers_hyp / N)\n",
    "    \n",
    "    \n",
    "    mean_poi = np.mean(blocked_fractions_poi)\n",
    "    mean_hype = np.mean(blocked_fractions_hype)\n",
    "    diff = mean_poi - mean_hype\n",
    "    std= np.std(np.array(blocked_fractions_poi)-np.array(blocked_fractions_hype))\n",
    "    conf_int = stats.norm.interval(0.95, loc=diff, scale=std / np.sqrt(n))\n",
    "\n",
    "    return np.array(blocked_fractions_poi)-np.array(blocked_fractions_hype), diff, conf_int\n",
    "\n",
    "generator = lambda: Exp_service_time(mst)\n",
    "# Run simulations\n",
    "blocked_fractions_1,mean, conf_int = CommonRandomNumbers(m,mst, mtbc,n,N,generator) \n",
    "\n",
    "# Print results\n",
    "print(f\"Mean: {mean:.4f}\")\n",
    "print(f\"95% confidence interval: ({conf_int[0]:.4f}, {conf_int[1]:.4f})\")\n",
    "\n",
    "# No difference ??? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma^2 = 1\n",
      "\n",
      "For a = 2:\n",
      "\n",
      "Sample size = 1000:\n",
      "Crude Monte Carlo Estimator: 0.024\n",
      "Importance Sampling Estimator: 0.5096938845613809\n",
      "\n",
      "Sample size = 5000:\n",
      "Crude Monte Carlo Estimator: 0.022\n",
      "Importance Sampling Estimator: 0.49543485671304904\n",
      "\n",
      "Sample size = 10000:\n",
      "Crude Monte Carlo Estimator: 0.0229\n",
      "Importance Sampling Estimator: 0.4996020353681839\n",
      "\n",
      "For a = 4:\n",
      "\n",
      "Sample size = 1000:\n",
      "Crude Monte Carlo Estimator: 0.0\n",
      "Importance Sampling Estimator: 0.4951835287861722\n",
      "\n",
      "Sample size = 5000:\n",
      "Crude Monte Carlo Estimator: 0.0\n",
      "Importance Sampling Estimator: 0.5080669779410953\n",
      "\n",
      "Sample size = 10000:\n",
      "Crude Monte Carlo Estimator: 0.0\n",
      "Importance Sampling Estimator: 0.5045255348948406\n",
      "\n",
      "Efficiency Discussion:\n",
      "Importance sampling tends to be more efficient when the tails of the distribution are important. It achieves this by assigning higher probabilities to rare events, thereby reducing variance compared to crude Monte Carlo.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Crude Monte Carlo estimator for P(Z > a)\n",
    "def crude_monte_carlo(a, num_samples):\n",
    "    samples = np.random.randn(num_samples)  # generate standard normal samples\n",
    "    probability = np.mean(samples > a)\n",
    "    return probability\n",
    "\n",
    "# Importance sampling\n",
    "def importance_sampling(a, sigma, num_samples):\n",
    "    samples = np.random.normal(loc=a, scale=sigma, size=num_samples)  # generate samples from normal density with mean a and variance sigma^2\n",
    "    weights = np.exp(-0.5 * ((samples - a) / sigma) ** 2) / (sigma * np.sqrt(2 * np.pi))  # compute importance weights\n",
    "    probability = np.mean((samples > a) * weights) / np.mean(weights)  # estimate probability using importance weights\n",
    "    return probability\n",
    "\n",
    "# Experimentation\n",
    "sample_sizes = [1000, 5000, 10000]  # different sample sizes\n",
    "a_values = [2, 4]  # different values of 'a'\n",
    "sigma_values = [1]  # different values of sigma^2\n",
    "\n",
    "for sigma in sigma_values:\n",
    "    print(f\"Sigma^2 = {sigma}\")\n",
    "    for a in a_values:\n",
    "        print(f\"\\nFor a = {a}:\")\n",
    "        for num_samples in sample_sizes:\n",
    "            print(f\"\\nSample size = {num_samples}:\")\n",
    "            # Crude Monte Carlo\n",
    "            crude_prob = crude_monte_carlo(a, num_samples)\n",
    "            print(\"Crude Monte Carlo Estimator:\", crude_prob)\n",
    "            # Importance Sampling\n",
    "            importance_prob = importance_sampling(a, sigma, num_samples)\n",
    "            print(\"Importance Sampling Estimator:\", importance_prob)\n",
    "\n",
    "# Efficiency Discussion\n",
    "print(\"\\nEfficiency Discussion:\")\n",
    "print(\"Importance sampling tends to be more efficient when the tails of the distribution are important. It achieves this by assigning higher probabilities to rare events, thereby reducing variance compared to crude Monte Carlo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7177326610281662\n",
      "Estimated value: 34096305.04034875\n"
     ]
    }
   ],
   "source": [
    "U = np.random.uniform(0, 1, num_samples)\n",
    "X = np.exp(U)\n",
    "mean = np.mean(X)\n",
    "print(mean)\n",
    "# Original function f(x) = e^x\n",
    "def f(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "# Importance sampling function g(x) = lambda * exp(-lambda * x)\n",
    "def g(x, lmbda):\n",
    "    return lmbda * np.exp(-lmbda * x)\n",
    "\n",
    "# Importance sampling estimator\n",
    "def importance_sampling_estimator(lmbda, num_samples):\n",
    "    samples = np.random.exponential(scale=1/lmbda, size=num_samples)  # generate samples from exponential distribution\n",
    "    weights = f(samples) / g(samples, lmbda)  # compute importance weights\n",
    "    estimate = np.mean(weights)\n",
    "    return estimate\n",
    "\n",
    "# Parameters\n",
    "lmbda = 1  # lambda value for the exponential distribution\n",
    "num_samples = 100000  # number of samples\n",
    "\n",
    "# Estimate integral using importance sampling\n",
    "estimate = importance_sampling_estimator(lmbda, num_samples)\n",
    "print(\"Estimated value:\", estimate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
